# =================================================
# IMPORTS (ÙƒÙˆØ¯Ùƒ + Ø¥Ø¶Ø§ÙØ§Øª GPT)
# =================================================
import streamlit as st
import pandas as pd
import numpy as np
from openai import OpenAI


# =================================================
# OPENAI CLIENT
# =================================================
# Ø­Ø·ÙŠ Ø§Ù„Ù…ÙØªØ§Ø­ ÙÙŠ .streamlit/secrets.toml
# OPENAI_API_KEY="sk-xxxx"
client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])


# =================================================
# LANGUAGE HELPER (ÙƒÙ…Ø§ ØªØ³ØªØ®Ø¯Ù…ÙŠÙ†Ù‡)
# =================================================
def t(en, ar):
    return en if st.session_state.get("lang", "AR") == "EN" else ar


# =================================================
# SESSION STATE
# =================================================
if "lang" not in st.session_state:
    st.session_state.lang = "AR"

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []


# =================================================
# MOCK DATA (Ù†ÙØ³ ÙÙƒØ±ØªÙƒ)
# =================================================
area_data = pd.DataFrame({
    "Area": ["North Riyadh"],
    "Demand_Index": [80],
    "Risk_Score": [40],
    "Avg_Price": [5200]
})

selected_area = "North Riyadh"
predicted_price = 6100
recommendation = "Strong Buy"


# =================================================
# UI (ÙƒÙˆØ¯Ùƒ ÙƒÙ…Ø§ Ù‡Ùˆ)
# =================================================
st.markdown(t("## ğŸ’¬ AI Investment Assistant", "## ğŸ’¬ Ù…Ø³Ø§Ø¹Ø¯ Ø§Ø³ØªØ«Ù…Ø§Ø±ÙŠ Ø°ÙƒÙŠ"))

st.markdown(t(
    "Ask SmartProp AI about this market",
    "Ø§Ø³Ø£Ù„ÙŠ SmartProp AI Ø¹Ù† Ù‡Ø°Ø§ Ø§Ù„Ø³ÙˆÙ‚"
))

user_question = st.text_input(
    t("Type your question here...", "Ø§ÙƒØªØ¨ÙŠ Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§...")
)


# =================================================
# ORIGINAL RULE-BASED FUNCTION (ÙƒÙˆØ¯Ùƒ 100%)
# =================================================
def ai_chat_response(question, area_data, predicted_price, recommendation):
    demand = area_data["Demand_Index"].values[0]
    risk = area_data["Risk_Score"].values[0]
    current_price = area_data["Avg_Price"].values[0]

    if "why" in question.lower() or "Ù„ÙŠØ´" in question:
        return t(
            f"The recommendation is based on demand ({demand}) and risk ({risk}). "
            f"High demand with controlled risk supports this decision.",
            f"Ø§Ù„ØªÙˆØµÙŠØ© Ù…Ø¨Ù†ÙŠØ© Ø¹Ù„Ù‰ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø·Ù„Ø¨ ({demand}) ÙˆØ§Ù„Ù…Ø®Ø§Ø·Ø±Ø© ({risk}). "
            f"Ø§Ù„Ø·Ù„Ø¨ Ø§Ù„Ù…Ø±ØªÙØ¹ Ù…Ø¹ Ù…Ø®Ø§Ø·Ø±Ø© Ù…ØªØ­ÙƒÙ… Ø¨Ù‡Ø§ ÙŠØ¯Ø¹Ù… Ù‡Ø°Ø§ Ø§Ù„Ù‚Ø±Ø§Ø±."
        )

    if "good" in question.lower() or "Ø§Ø³ØªØ«Ù…Ø§Ø±" in question:
        return t(
            f"Based on AI analysis, {selected_area} shows a predicted price of "
            f"{int(predicted_price)} SAR/mÂ² compared to the current {current_price}. "
            f"This suggests: {recommendation}.",
            f"Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠØŒ Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ù…ØªÙˆÙ‚Ø¹ ÙÙŠ {selected_area} Ù‡Ùˆ "
            f"{int(predicted_price)} Ø±ÙŠØ§Ù„/Ù…Â² Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ {current_price}. "
            f"ÙˆÙ‡Ø°Ø§ ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰: {recommendation}."
        )

    if "compare" in question.lower() or "Ù‚Ø§Ø±Ù†" in question:
        return t(
            "Comparison across areas is available in the Enterprise version.",
            "Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨ÙŠÙ† Ø§Ù„Ù…Ù†Ø§Ø·Ù‚ Ù…ØªØ§Ø­Ø© ÙÙŠ Ù†Ø³Ø®Ø© Ø§Ù„Ø´Ø±ÙƒØ§Øª."
        )

    # ğŸ‘‡ Ù…Ù‡Ù…: Ù„Ùˆ Ù…Ø§ Ø¹Ø±Ù ÙŠØ¬Ø§ÙˆØ¨
    return None


# =================================================
# GPT FALLBACK (Ø¥Ø¶Ø§ÙØ© ÙÙ‚Ø·)
# =================================================
def gpt_response(question, area_data):
    context = f"""
    Area: {area_data['Area'].values[0]}
    Demand Index: {area_data['Demand_Index'].values[0]}
    Risk Score: {area_data['Risk_Score'].values[0]}
    Avg Price: {area_data['Avg_Price'].values[0]} SAR/mÂ²
    """

    completion = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {
                "role": "system",
                "content": "You are a professional real estate investment AI assistant. Answer clearly and professionally."
            },
            {
                "role": "user",
                "content": context + "\n\nQuestion: " + question
            }
        ]
    )

    return completion.choices[0].message.content


# =================================================
# SMART WRAPPER (Rules â†’ GPT)
# =================================================
def smart_ai_response(question):
    rule_answer = ai_chat_response(
        question,
        area_data,
        predicted_price,
        recommendation
    )

    if rule_answer is not None:
        return rule_answer

    return gpt_response(question, area_data)


# =================================================
# EXECUTION
# =================================================
if user_question:
    with st.spinner(t("SmartProp AI is thinking...", "SmartProp AI ÙŠÙÙƒØ±...")):
        answer = smart_ai_response(user_question)

        st.session_state.chat_history.append({
            "question": user_question,
            "answer": answer
        })

    st.success(answer)


# =================================================
# CHAT HISTORY
# =================================================
if st.session_state.chat_history:
    st.markdown(t("### ğŸ§  Chat History", "### ğŸ§  Ø³Ø¬Ù„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©"))

    for chat in reversed(st.session_state.chat_history):
        st.markdown(f"**ğŸ§‘â€ğŸ’¼ {chat['question']}**")
        st.info(chat["answer"])
